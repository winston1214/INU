{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 코로나 시작일 1월 23일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기간 설정 : 2019.01.23 ~ 2021.01.23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 삼전,네이버,기업은행,셀트리온,씨젠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~2021-10-12 : 50 counts\n",
      "~2021-10-06 : 100 counts\n",
      "~2021-09-27 : 150 counts\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from urllib.request import urlopen,Request\n",
    "import urllib\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "import re\n",
    "# selenium start\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\"); # 시작할때 최대창을 띄워라\n",
    "browser = webdriver.Chrome('chromedriver', options=options)\n",
    "company = ['samsung-electronics-co-ltd','naver-corp','industrial-bank-of-korea','celltrion-inc','seegene-inc']\n",
    "for c in company:\n",
    "    url = f'https://kr.investing.com/equities/{}-scoreboard'\n",
    "    browser.get(url) # 사이트 접속\n",
    "    time.sleep(1)\n",
    "    html = browser.page_source\n",
    "    soup = bs4.BeautifulSoup(html, 'html')\n",
    "    # compare up & down\n",
    "    up_string = 'newSiteIconsSprite newSmallBullIcon2 inlineblock middle'\n",
    "    down_string = 'newSiteIconsSprite newSmallBearIcon2 inlineblock middle'\n",
    "    up_string = up_string.replace(' ','.')\n",
    "    down_string = down_string.replace(' ','.')\n",
    "    # feature setting\n",
    "    start = 1\n",
    "    last = 0\n",
    "    date_index = []\n",
    "    matrix = soup.select('#sentiments_table > tbody >tr')\n",
    "\n",
    "    korean = re.compile('[\\u3131-\\u3163\\uac00-\\ud7a3]+')\n",
    "\n",
    "    # start date & end_date\n",
    "    START_DATE = '2021-9-30'\n",
    "    END_DATE = '2021-10-15'\n",
    "    start_date = dt.datetime.strptime(START_DATE, \"%Y-%m-%d\")\n",
    "    end_date = dt.datetime.strptime(END_DATE, \"%Y-%m-%d\")\n",
    "    c = 0\n",
    "    while (end_date >= start_date):\n",
    "        date_index.append(end_date.strftime(\"%Y-%m-%d\"))\n",
    "        end_date = end_date - timedelta(days = 1)\n",
    "\n",
    "    st = dt.datetime.strptime(START_DATE, \"%Y-%m-%d\")\n",
    "    end = END_DATE\n",
    "    # counting = 0\n",
    "    df = pd.DataFrame({'date':date_index,'up_count':0,'down_count':0})\n",
    "\n",
    "    while dt.datetime.strptime(end, \"%Y-%m-%d\") >= st:\n",
    "\n",
    "        matrix = soup.select('#sentiments_table > tbody >tr')\n",
    "        last += len(matrix)\n",
    "        for i in range(start,last+1):\n",
    "            icon = browser.find_element_by_css_selector(f'#sentiments_table > tbody > tr:nth-child({i}) > td.center')\n",
    "            today_date = browser.find_element_by_css_selector(f'#sentiments_table > tbody > tr:nth-child({i}) > td.first.left').text.strip()\n",
    "            today_date = today_date.replace(' ','')\n",
    "            end = re.sub(korean,'-',today_date)[:-1]\n",
    "\n",
    "            try:\n",
    "                icon.find_element_by_class_name(down_string)\n",
    "                df.loc[df.date == end,'down_count'] += 1\n",
    "            except:\n",
    "                icon.find_element_by_class_name(up_string)\n",
    "                df.loc[df.date == end,'up_count'] += 1\n",
    "        browser.find_element_by_xpath('//*[@id=\"moreLink\"]').click() # 더보기 클릭\n",
    "        start = last\n",
    "        time.sleep(3)\n",
    "        print(f'{c}~{end} : {last} counts')\n",
    "    df.to_csv(f'{}_investing.csv',index=False)\n",
    "browser.quit()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_index = []\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "START_DATE = '2019-09-23'\n",
    "END_DATE = '2020-01-23'\n",
    "start_date = dt.datetime.strptime(START_DATE, \"%Y-%m-%d\")\n",
    "end_date = dt.datetime.strptime(END_DATE, \"%Y-%m-%d\")\n",
    "while (end_date >= start_date):\n",
    "    date_index.append(end_date.strftime(\"%Y-%m-%d\"))\n",
    "    end_date = end_date - timedelta(days = 1)\n",
    "date_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.datetime.strptime(END_DATE, \"%Y-%m-%d\") >= dt.datetime.strptime(START_DATE, \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icon.find_element_by_class_name(up_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "for _ in range(2):\n",
    "    ls = soup.find_all('td',attrs={'class':'center'})\n",
    "    up_string = 'newSiteIconsSprite newSmallBullIcon2 inlineblock middle'\n",
    "    down_string = 'newSiteIconsSprite newSmallBearIcon2 inlineblock middle'\n",
    "    updown = np.array([None for i in range(len(ls))])\n",
    "    for i,data in enumerate(ls):\n",
    "        if data.find_all('span',attrs={'class':up_string}):\n",
    "            updown[i] = '100'\n",
    "        elif data.find_all('span',attrs={'class':down_string}):\n",
    "            updown[i] = '-1'\n",
    "    updown = updown[np.where(updown != None)]\n",
    "    day = soup.find_all('td',attrs={'class':'first left'})\n",
    "    day = [i.text for i in day]\n",
    "    df = pd.DataFrame({'date':day,'updown':updown})\n",
    "    df_list.append(df)\n",
    "    browser.find_element_by_xpath('//*[@id=\"moreLink\"]').click() # 더보기 클릭\n",
    "    idx += 1\n",
    "df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\"); # 시작할때 최대창을 띄워라\n",
    "browser = webdriver.Chrome('chromedriver', options=options)\n",
    "url = 'https://kr.investing.com/equities/samsung-electronics-co-ltd-scoreboard'\n",
    "browser.get(url) # 사이트 접속\n",
    "html = browser.page_source\n",
    "soup = bs4.BeautifulSoup(html, 'html')\n",
    "browser.find_element_by_css_selector('#sentiments_table > tbody > tr:nth-child(49) > td.first.left').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiments_table > tbody > tr:nth-child(49) > td.first.left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Oct 28 15:43:56 2020\n",
    "\n",
    "@author: Jayleen\n",
    "\n",
    "for faster crawling\n",
    "\"\"\"\n",
    "\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "# import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "invesco = [\"AAPL\", \"AMZN\", \"MSFT\", \"FB\", \"GOOGL\", \"TSLA\", \"GOOG\", \"NVDA\", \"ADBE\", \"NFLX\"]\n",
    "# START_DATE = '2019-12-01'\n",
    "START_DATE = \"2019-12-01\"\n",
    "# END_DATE = '2020-09-01'\n",
    "END_DATE = '2020-01-26'\n",
    "site = [\"apple-computer-inc\", \"amazon-com-inc\", \"microsoft-corp\", \"facebook-inc\", \"google-inc\",\n",
    "         \"tesla-motors\", \"google-inc-c\", \"nvidia-corp\", \"adobe-sys-inc\", \"netflix,-inc.\"]\n",
    "\n",
    "# tick\n",
    "k = 5\n",
    "\n",
    "# basic Date Dataframe\n",
    "date_index = []\n",
    "bd = dt.datetime.strptime(END_DATE, '%Y-%m-%d')\n",
    "\n",
    "while (bd >= dt.datetime.strptime(START_DATE, \"%Y-%m-%d\")):\n",
    "    date_index.append(bd.strftime(\"%Y-%m-%d\"))\n",
    "    bd = bd - timedelta(days = 1)\n",
    "\n",
    "DATE = pd.DataFrame({\"date\": date_index})\n",
    "\n",
    "#%%\n",
    "bullbear = pd.DataFrame({\"Date\": date_index, '%s_Bullish' %invesco[k]: 0, '%s_Bearish' %invesco[k]: 0})\n",
    "\n",
    "# def FasterInvesting(url, qqq):\n",
    "driver = webdriver.Chrome(\"./chromedriver\")\n",
    "driver.get(\"https://www.investing.com/equities/%s-scoreboard\" %site[k]) #헤더 필요없음\n",
    "time.sleep(1)\n",
    "print(\"------ %s crawling ------\" %invesco[k])\n",
    "\n",
    "\n",
    "d = END_DATE\n",
    "start = 1\n",
    "c = 1\n",
    "\n",
    "print(\"..start\")\n",
    "# try:\n",
    "    \n",
    "while (dt.datetime.strptime(d, \"%Y-%m-%d\") >= dt.datetime.strptime(START_DATE, \"%Y-%m-%d\")):\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    last = len(soup.select(\"#sentiments_table > tbody > tr\"))\n",
    "\n",
    "    for i in range(start, last + 1):\n",
    "        \n",
    "        counting = 1\n",
    "        d = driver.find_element_by_css_selector(\"#sentiments_table > tbody > tr:nth-child(%d) > td.first.left\" %i).text.strip()\n",
    "        d = dt.datetime.strptime(d, \"%b %d, %Y\").strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        if dt.datetime.strptime(d, \"%Y-%m-%d\") > dt.datetime.strptime(END_DATE, \"%Y-%m-%d\"):\n",
    "            start = last\n",
    "            break\n",
    "        # r = driver.find_element_by_css_selector(\"#sentiments_table > tbody > tr:nth-child(%d) > td:nth-child(4)\" %i).text.strip()\n",
    "        # openRate.append(r)\n",
    "\n",
    "        icon = driver.find_element_by_css_selector(\"#sentiments_table > tbody > tr:nth-child(%d) > td.center\" %i)\n",
    "        try :\n",
    "            icon.find_element_by_class_name(\"newSiteIconsSprite.newSmallBullIcon2.inlineblock.middle\")\n",
    "            bullbear.loc[bullbear.Date == d, '%s_Bullish' %invesco[k]] += counting\n",
    "        except :\n",
    "            icon.find_element_by_class_name(\"newSiteIconsSprite.newSmallBearIcon2.inlineblock.middle\")\n",
    "            bullbear.loc[bullbear.Date == d, '%s_Bearish' %invesco[k]] += counting\n",
    "            \n",
    "        start = last\n",
    "\n",
    "    driver.find_element_by_css_selector(\"#moreLink\").click()\n",
    "    print(\"%d click %s\" %(c, d))\n",
    "    c += 1\n",
    "    time.sleep(2)\n",
    "\n",
    "#%%    \n",
    "if os.path.exists('BullBear_%s.csv' %invesco[k]):\n",
    "    bullbear.to_csv('BullBear_%s.csv' %invesco[k], index = False, mode = 'a', encoding = 'utf-8', header = False) #utf-8-sig: 한글\n",
    "else:\n",
    "    bullbear.to_csv('BullBear_%s.csv' %invesco[k], index = False, mode = 'w', encoding = 'utf-8')\n",
    "    \n",
    "print(\"load data: 총 %d개\" %last)\n",
    "    \n",
    "# df = pd.DataFrame({\"date\" : date, \"Bullish\": bullish, \"Bearish\": bearish})\n",
    "driver.close()\n",
    "    \n",
    "    # return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
